<!doctype html>
<html lang="en">

<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="description" content="">
  <title>Group 23 - EDA</title>

  <!-- CSS only -->
  <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.2.0/dist/css/bootstrap.min.css" rel="stylesheet"
    integrity="sha384-gH2yIJqKdNHPEq0n4Mqa/HGKIhSkIHeL5AyhkYV8i59U5AR6csBvApHHNl/vI1Bx" crossorigin="anonymous">
  <link href="/docs/5.2/dist/css/bootstrap.min.css" rel="stylesheet"
    integrity="sha384-gH2yIJqKdNHPEq0n4Mqa/HGKIhSkIHeL5AyhkYV8i59U5AR6csBvApHHNl/vI1Bx" crossorigin="anonymous">

  <!-- Favicons -->

  <!-- Custom styles for this template -->
  <link href="css/styles.css" rel="stylesheet">
</head>

<body>

  <!-- Navbar -->
  <div class="container" style="max-width: 800px">
    <nav class="navbar mx-auto bg-light px-4 fixed-top">
      <a class="navbar-brand" href="index.html">Big Data and Cloud Computing - Final Project</a>
      <ul class="nav nav-pills justify-content-center">
        <li class="nav-item"><a class="nav-link" href="index.html#projectIntroduction" style="color: black">Project
            Introduction</a></li>
        <li class="nav-item"><a class="nav-link" href="index.html#aboutTeam" style="color: black">About the Team</a>
        </li>
        <li class="nav-item"><a class="nav-link" href="EDA.html" style="color: black">EDA</a></li>
        <li class="nav-item"><a class="nav-link" href="NLP.html" style="color: black">NLP</a></li>
      </ul>
    </nav>





    <br>
    <h2>Natural Language Processing</h2>
    <hr>
    <br>

    <p>
      The goal of our analysis:
    <ol>
      <li>(Xinlu) Common words, Important words,.......</li>
      <li>Sentiment Analysis.........</li>
      <li>Topic Modeling......</li>
      <li>Combine NLP with external data</li>
    </ol>
    </p>
    <br>
    <br>
    <br>



    <hr>
    <h4>
      Data Cleaning
    </h4>

    <p>
      Our text data sets are the Reddit comments and submissions from January 1, 2022 to August 31, 2022, amounting to
      10,378,762 unique articles. For submission posts, "title" and "selftext" are concatenated. We leverage Apache
      Spark and Spark NLP to build the text processing pipeline. First, we used the pre-trained model
      “detect_language_375” provided by John Snow Labs, to detect the languages of each post and estimate the language
      proportion from 0 to 1. We include posts in Ukrainian, Russian, and English, and create three sub-datasets for
      each of them by selecting posts with an estimated proportion above 0.8 for that language. Secondly, we remove
      posts with “[removed]”, “[deleted]”, and “[deleted by user]”. Thirdly, we apply common natural language text
      cleaning procedures including 1) changing all words into lower case, lowercase; 2) removing numbers,
      punctuations,and stopwords; 3) lemmatizing each word to its single format, e.g. "words" to "word", "makes" to
      "make".
    </p>
    <p>
      We collect the commodity futures' price data from investing.com. The data has the same date range as the Reddit
      data from January 1, 2022 to August 31, 2022, covering 15 major food and energy commodities. To calculate the
      returns, we use daily close-to-close prices.
    </p>



    <br>
    <br>
    <br>
    <!-- Q1 -->
    <hr>
    <h4>Q1. (NLP) What are the major topics discussed in Reddit related to Russia Ukraine conflict?</h4>
    <br>
    <p>
      <strong>Topic models</strong> generate interpretable text features extracted from documents. These models help
      identify and cluster similar documents and are useful tools to tag documents.
    </p>

    <p><a href="https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.ml.clustering.LDA.html">Spark
        MLlib documentation</a> specifies the terminology used in this analysis: Link</p>
    <ol>
      <li><mark>term = word</mark>: an element of the vocabulary</li>
      <li><mark>token</mark>: instance of a term appearing in a document</li>
      <li><mark>topic</mark>:multinomial distribution over terms representing some concept</li>
      <li><mark>document</mark>: one piece of text, corresponding to one row in the input data</li>
    </ol>

    <br>






    <h4>
      Latent Dirichlet Allocation (LDA)
    </h4>
    <p>
      <strong>Latent Dirichlet Allocation (LDA)</strong> is a statistical model that helps produce meaningful topics
      that humans can relate to. It assumes that topics are probability distributions over words, and documents are
      distributions over topics and that topics use only a limited number of terms frequently.
    </p>

    <ul>
      <li><mark>k</mark>: number of topics (= number of clusters)</li>
      <li><mark>maxIter</mark>: number of iterations</li>
      <li><mark>featuresCol</mark>: a collection of documents as input data. Feature transformers such as
        <strong>Tokenizer</strong> and <strong>CountVectorizer</strong> are used to convert text to word count vectors
        as input data.
      </li>
    </ul>
    <br>

    <h4>
      Topic Modeling Pipeline
    </h4>
    <p>
      We proceed with 15 topics, top 10 words per topic using the cleaned documents as input data. The <a
        href="https://colab.research.google.com/drive/14bf2kwdU4f5UBUYEkTJO01NjFtWEZU_-#scrollTo=yqwgYNlgwxvX">notebook</a>
      contains the LDA pipeline applied to the submissions and comments data. The data from two sources are stacked
      using <mark>union</mark> command to provide comprehensive topic modeling on every posts related to RU Conflict in
      the Reddit dataset.
    </p>

    <!-- IMAGE: LDA PIPELINE -->
    <div class="row py-5">

      <div class="col-md-12">
        <div class="card p-0" style="border: none">
          <img src="img/NLP/pipeline.png" class="card-img-top" alt="...">
          <div class="card-body">
            <p style="font-weight: lighter; text-align: center;"><strong>FIGURE ## </strong>LDA Pipeline</p>
          </div>
        </div>
      </div>
    </div>
    <!-- IMAGE END -->


    <br>
    <hr>
    <h4>Q2. (NLP) What are different languages other than English that can be analyzed in the Dataset? (language
      detection) Xinlu</h4>
    <p>
      Although it is easy to assume that most of the Reddit content is in English, based on the chosen topics, we target
      English, Ukrainian, and Russian as the languages of interest. To categorize the submission records by language, we
      use Spark NLP pre-trained language detection model <b>detect_language_375</b>. We obtain the prediction confidence
      toward these three languages for each submission and comment content. With the confidence values, we can define
      dummy variables for three languages by any desired bar. For the NLP part of our project, we subset our data by
      their language with 80% confidence. We conduct our common word analysis using PySpark SQL functions, following the
      process of tokenizing, aggregating by vocabulary, counting, and sorting. We obtain the TFIDF scores for our
      vocabularies using PySpark machine learning feature algorithms. The extraction and transformation tools include
      <b>Tokenizer</b>, <b>HashingTF</b>, <b>IDF</b>. We map the resulting TFIDF score to words by user-defined
      functions under the PySpark SQL environment. Since we are dealing with foreign languages, we also utilize Spark
      NLP pre-trained pipeline <b>translate_ru_en</b> and <b>translate_uk_en</b>, enabling translation from Russian and
      Ukrainian to English, respectively. When we only need the translation for word tokens, we use the pipelines start
      with document assembler, followed by the Spark Neural Machine Translation framework <b>Marian</b> models
      <b>opus_mt_ru_en</b> and <b>opus_mt_uk_en</b> respectively. The results we obtain give us insights into how the
      focus of the discussion in different languages varies from each other. However, since there is a significant gap
      between the volume of records in English and the volume of records in Russian and Ukrainian, we will not include
      records in these languages in our further explorations.
    </p>







    <br>
    <br>

    <br>
    <hr>
    <h4>Q3. Which topics/kinds of submissions/comments are more popular?</h4>

    <p>
      Applying the TFIDF method to our text data gives us more insight into online discussions. With the <b>pyspark</b>
      machine learning features and annotators, we feed our cleaned text data through the tokenizer. And then conduct
      hashing term frequency transformation for the tokenized column. HashingTF enables dimensionality reduction to the
      dataset, which is very helpful when working on large-sized data in a distributive manner. We then compute the
      inversed document frequency for each TF vector corresponding to the text records. By extracting function
      properties and annotator returns, we map the TFIDF score back to the textual word tokens and sort them to find the
      most important words. Please refer to <a
        href="https://github.com/gu-anly502/fall-2022-project-eda-adb-project-group-23/TFIDF.ipynb">this notebook</a>
      for calculating the TF-IDF scores.
    </p>
    <p>
      TFIDF helps us discard the dominance of words like country names and wars. The critical words give us different
      perspectives of the discussion. We can see political or geometrical representations like <i>European, German, and
        Belarus</i>. Words like <i>brigade</i>, <i> combat</i>, and </i> front</i> imply more detailed descriptions and
      discussion going on in the military-related discussion. The nickname "Dr. Eisenfaust." for the Mayer of Kyiv
      brings up a new political figure other than Putin. Instead of nouns, more adjectives appearing as important words
      bring out the discussion nature of Reddit.
    </p>

    <br>

    <div class="table-responsive">
      <table class="table">
        <tr>
          <th>Language</th>
          <th>Reddit Subset</th>
          <th>Top 10 common words by word counts</th>
          <th>Top 10 important words by TF-IDF</th>
        </tr>
        <tr>
          <th rowspan="2" style="vertical-align: middle;">English</th>
          <th style="vertical-align: middle;">submission</th>
          <td><i>ukraine</i>, <i>russian</i>, <i>russia</i>, <i>ukrainian</i>, <i>war</i>, <i>putin</i>, <i>people</i>,
            <i>forces</i>, <i>military</i>, <i>russians</i>
          </td>
          <td><i>european</i>, <i>german</i>, <i>full</i>, <i>man</i>, <i>belarus</i>, <i>combat</i>, <i>avoided</i>,
            <i>left</i>, <i>brigade</i>, <i>front</i>
          </td>
        </tr>
        <tr>
          <th style="vertical-align: middle;">comment</th>
          <td><i>russia</i>, <i>ukraine</i>, <i>russian</i>, <i>war</i>, <i>people</i>, <i>putin</i>, <i>russians</i>,
            <i>ukrainian</i>, <i>time</i>, <i>good</i>
          </td>
          <td><i>hypercompetence</i>, <i>yourse</i>, <i>irepepctive</i>, <i>feeeeeeeelings</i>, <i>favorably</i>,
            <i>eisenfaust</i>, <i>cowy</i>, <i>trackers</i>, <i>correctlynused</i>, <i>isayevich</i>
          </td>
        </tr>
        <tr>
          <th rowspan="2" style="vertical-align: middle;">Russian</th>
          <th style="vertical-align: middle;">submission</th>
          <td><i>России(Russian Federation)</i>, <i>войны(War)</i>, <i>Путин(Putin)</i>, <i>США(United States
              dollars)</i>, <i>время(time)</i>, <i>своих(your own)</i>, <i>Зеленский(Green)</i>,
            <i>территории(Territory)</i>, <i>мир(peace)</i>, <i>Бабченко:(Babchenko:)</i>,
          </td>
          <td><i>других(Other)</i>, <i>работает(working)</i>, <i>города(Cities)</i>, <i>день(day)</i>,
            <i>помощи(assistance)</i>, <i>вся(All of them.)</i>, <i>детей(Children)</i>, <i>российской(Russian)</i>,
            <i>куклу(Doll)</i>, <i>мира(peace)</i>
          </td>
        </tr>
        <tr>
          <th style="vertical-align: middle;">comment</th>
          <td><i>России(Russian Federation)</i>, <i>Украине(Ukraine)</i>, <i>люди(people)</i>, <i>людей(of human
              beings)</i>, <i>войны(War)</i>, <i>Путин(Putin)</i>, <i>человек(Total population)</i>,
            <i>страны(Country)</i>, <i>НАТО(NATO)</i>, <i>США(United States dollars)</i>,
          </td>
          <td><i>начали(Start)</i>, <i>своим(your own)</i>, <i>ситуации(situation)</i>, <i>россияне(Russians)</i>,
            <i>самом(I'm not sure.)</i>, <i>шмольцы(Shh.)</i>, <i>человека(Human Rights)</i>, <i>страна(Country)</i>,
            <i>ребята…(Guys...)</i>, <i>мир(peace)</i>
          </td>
        </tr>
        <tr>
          <th rowspan="2" style="vertical-align: middle;">Ukrainian</th>
          <th style="vertical-align: middle;">submission</th>
          <td><i>України(Ukraine)</i>, <i>Росії(Russia)</i>, <i>війни(wars)</i>, <i>РФ(RF)</i>, <i>США(United
              States)</i>, <i>людей(people)</i>, <i>Слава(Glory)</i>, <i>вторгнення(invasion)</i>,
            <i>окупантів(Occupationals)</i>, <i>дітей(kids)</i>
          </td>
          <td><i>російська(grow up)</i>, <i>останнім(Permanent)</i>, <i>дорослих(The older)</i>, <i>дорозі(Dorose)</i>,
            <i>думкою(Thoughtful)</i>, <i>олександра(olexandra)</i>, <i>дізнатися(to know)</i>, <i>дія(the United
              Nations)</i>, <i>експертів(Suppliers)</i>, <i>translate(transfer)</i>
          </td>
        </tr>
        <tr>
          <th style="vertical-align: middle;">comment</th>
          <td><i>України(Ukraine)</i>, <i>людей(people)</i>, <i>війни(wars)</i>, <i>взагалі(generally)</i>,
            <i>питання(question)</i>, <i>країни(countries)</i>, <i>Слава(Glory)</i>, <i>Росії(Russia)</i>, <i>США(United
              States)</i>, <i>життя(life)</i>
          </td>
          <td><i>повномасштабному(large scale)</i>, <i>наприклад(Apparatus)</i>, <i>гроші(for a little while)</i>,
            <i>замінив(Deputy)</i>, <i>українців(Theft)</i>, <i>росії(and grow up)</i>, <i>microsoft(Microsoft)</i>,
            <i>supermarkety(Supermarkety)</i>, <i>автократії(autocratic)</i>, <i>аккаунт(account)</i>
          </td>
        </tr>
      </table>
      <p style="font-weight: lighter; text-align: center;"><strong>TABLE ##</strong> Common/Important words found from
        applying tf-idf</p>
    </div>

    <br>


    <p>
      As we tagged all the submissions and comments by their languages, we split the datasets into English, Russian, and
      Ukrainian since they are part of the focus of our textual analysis.
    </p>
    <p>
      Common words can help us find what has frequently been brought up by people when making comments and posts under
      our selected subreddits. Inside the spark environment, we explode the body of the comments and submissions into
      single words. By aggregating all the vocabularies by their counts, we are able to sort them to find the most
      common words over our time interval of interest. Please refer to <a
        href="https://github.com/gu-anly502/fall-2022-project-eda-adb-project-group-23/common_words_submission_comment_language.ipynb">this
        notebook</a> for the code extracting common words.
    </p>
    <p>
      For the comments and submissions in English, terms related to <i>war</i> appear naturally. The top few are the
      cognate words of countries, which come with the territory of the subreddits we selected. While we may also
      interpret part of the counts for <i>russian</i> and <i>ukrainian</i> as referring to the people. Combined with the
      fact that the word <i>people</i> is one of the most common words, we can find the humane and compassionate nature
      of the discussion. Moreover, among all the political leaders involved in the conflict, Putin gets most of the
      attention.
    </p>
    <p>
      Beyond the top ten words we listed, NATO and the US are the two other political entities that appear the most in
      the discussion. We also find curse words appear in high frequency, implying an extremely sentimental tone among
      the posts.
    </p>
    <p>
      The common words for posts in Russian and Ukrainian include words like US dollars and populations, which could
      suggest different angles of discussions like finance and geopolitics. Words like <i>Green</i> and <i>Babchenko</i>
      possibly represent political entries and figures that are not familiar to foreign people outside of the
      confliction area. While again, we can find words that describe <i>peace</i> and <i>human beings</i>.
    </p>

    <hr>



    <h4>Q8. How does each topic correlate to the commodity price changes?</h4>

    <p>
      It is a common practice to use correlation as preliminary analysis to test simple relationships between variables.
      Figure xx plots the Pearson correlations between all the timeseries we collected during the 8-month period.
    </p>

    <div class="row py-5">

      <div class="col-md-12">
        <div class="card p-0" style="border: none">
          <img src="img/NLP/correlations.png" class="card-img-top" alt="...">
          <div class="card-body">
            <p style="font-weight: lighter; text-align: center;"><strong>FIGURE ## </strong>Correlations between topics,
              sentiments, and commodity prices.</p>
          </div>
        </div>
      </div>
    </div>

    <p>
      The highlighting areas concentrate on the top-left and bottom-right corners, indicating there is strong
      relationship within
      commodity returns and reddit textual features, but not between them. Since our goal is to use reddit to predict
      commodity returns, a weak correlation between predictor and target implies we will need better features and a
      better-than-linear model.
    </p>
    <br>

    <hr>



    <br>
    <br>
    <br>
    <br>
    <br>
    <br>
    <br>













  </div> <!-- container -->


  <footer class="blog-footer">
    <p>
      <a href="#">Back to top</a>
    </p>
  </footer>



</body>

</html>